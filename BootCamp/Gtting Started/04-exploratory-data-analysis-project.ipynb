{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"../../resources/logo.png\" alt=\"Intellinum Bootcamp\" style=\"width: 400px; height: 200px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Exploratory Data Analysis\n",
    "Perform exploratory data analysis (EDA) to gain insights from a data lake.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "In `s3://data.intellinum.co/bootcamp/common/crime-data-2016`, there are a number of Parquet files containing 2016 crime data from seven United States cities:\n",
    "\n",
    "* New York\n",
    "* Los Angeles\n",
    "* Chicago\n",
    "* Philadelphia\n",
    "* Dallas\n",
    "* Boston\n",
    "\n",
    "\n",
    "The data is cleaned up a little, but has not been normalized. Each city reports crime data slightly differently, so\n",
    "examine the data for each city to determine how to query it properly.\n",
    "\n",
    "Your job is to use some of this data to gain insights about certain kinds of crimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing SparkSession detected\n",
      "Creating a new SparkSession\n"
     ]
    }
   ],
   "source": [
    "#MODE = \"LOCAL\"\n",
    "MODE = \"CLUSTER\"\n",
    "\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import json\n",
    "import math\n",
    "import numbers\n",
    "import numpy as np\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "sys.path.insert(0,'../../src')\n",
    "from settings import *\n",
    "\n",
    "try:\n",
    "    fh = open('../../libs/pyspark24_py36.zip', 'r')\n",
    "except FileNotFoundError:\n",
    "    !AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY} AWS_SECRET_ACCESS_KEY={AWS_SECRET_KEY} aws s3 cp s3://yuan.intellinum.co/bins/pyspark24_py36.zip ../../libs/pyspark24_py36.zip\n",
    "\n",
    "try:\n",
    "    spark.stop()\n",
    "    print(\"Stopped a SparkSession\")\n",
    "except Exception as e:\n",
    "    print(\"No existing SparkSession detected\")\n",
    "    print(\"Creating a new SparkSession\")\n",
    "\n",
    "SPARK_DRIVER_MEMORY= \"1G\"\n",
    "SPARK_DRIVER_CORE = \"1\"\n",
    "SPARK_EXECUTOR_MEMORY= \"1G\"\n",
    "SPARK_EXECUTOR_CORE = \"1\"\n",
    "SPARK_EXECUTOR_INSTANCES = 6\n",
    "\n",
    "\n",
    "\n",
    "conf = None\n",
    "if MODE == \"LOCAL\":\n",
    "    os.environ[\"PYSPARK_PYTHON\"] = \"/home/yuan/anaconda3/envs/pyspark24_py36/bin/python\"\n",
    "    conf = SparkConf().\\\n",
    "            setAppName(\"pyspark_day03_querying_json\").\\\n",
    "            setMaster('local[*]').\\\n",
    "            set('spark.driver.maxResultSize', '0').\\\n",
    "            set('spark.jars', '../../libs/mysql-connector-java-5.1.45-bin.jar').\\\n",
    "            set('spark.jars.packages','net.java.dev.jets3t:jets3t:0.9.0,com.google.guava:guava:16.0.1,com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.1')\n",
    "else:\n",
    "    os.environ[\"PYSPARK_PYTHON\"] = \"./MN/pyspark24_py36/bin/python\"\n",
    "    conf = SparkConf().\\\n",
    "            setAppName(\"pyspark_day03_querying_json\").\\\n",
    "            setMaster('yarn-client').\\\n",
    "            set('spark.executor.cores', SPARK_EXECUTOR_CORE).\\\n",
    "            set('spark.executor.memory', SPARK_EXECUTOR_MEMORY).\\\n",
    "            set('spark.driver.cores', SPARK_DRIVER_CORE).\\\n",
    "            set('spark.driver.memory', SPARK_DRIVER_MEMORY).\\\n",
    "            set(\"spark.executor.instances\", SPARK_EXECUTOR_INSTANCES).\\\n",
    "            set('spark.sql.files.ignoreCorruptFiles', 'true').\\\n",
    "            set('spark.yarn.dist.archives', '../../libs/pyspark24_py36.zip#MN').\\\n",
    "            set('spark.sql.shuffle.partitions', '5000').\\\n",
    "            set('spark.default.parallelism', '5000').\\\n",
    "            set('spark.driver.maxResultSize', '0').\\\n",
    "            set('spark.jars.packages','net.java.dev.jets3t:jets3t:0.9.0,com.google.guava:guava:16.0.1,com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.1'). \\\n",
    "            set('spark.driver.maxResultSize', '0').\\\n",
    "            set('spark.jars', 's3://yuan.intellinum.co/bins/mysql-connector-java-5.1.45-bin.jar')\n",
    "        \n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "    config(conf=conf).\\\n",
    "    getOrCreate()\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc.addPyFile('../../src/settings.py')\n",
    "\n",
    "sc=spark.sparkContext\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "hadoop_conf.set(\"fs.s3a.access.key\", AWS_ACCESS_KEY)\n",
    "hadoop_conf.set(\"fs.s3a.secret.key\", AWS_SECRET_KEY)\n",
    "hadoop_conf.set(\"mapreduce.fileoutputcommitter.algorithm.version\", \"2\")\n",
    "\n",
    "def display(df, limit=10):\n",
    "    return df.limit(limit).toPandas()\n",
    "\n",
    "def dfTest(id, expected, result):\n",
    "    assert str(expected) == str(result), \"{} does not equal expected {}\".format(result, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "Start by creating DataFrames for Los Angeles, Philadelphia, and Dallas data.\n",
    "\n",
    "Use `spark.read.parquet` to create named DataFrames for the files you choose. \n",
    "\n",
    "To read in the parquet file, use `crimeDataNewYorkDF = spark.read.parquet(\"s3a://data.intellinum.co/bootcamp/common/crime-data-2016/Crime-Data-New-York-2016.parquet\")`\n",
    "\n",
    "\n",
    "Use the following view names:\n",
    "\n",
    "| City          | DataFrame Name            | Path to S3 file\n",
    "| ------------- | ------------------------- | -----------------\n",
    "| Los Angeles   | `crimeDataLosAngelesDF`   | `s3://data.intellinum.co/bootcamp/common/crime-data-2016/Crime-Data-Los-Angeles-2016.parquet`\n",
    "| Philadelphia  | `crimeDataPhiladelphiaDF` | `s3://data.intellinum.co/bootcamp/common/crime-data-2016/Crime-Data-Philadelphia-2016.parquet`\n",
    "| Dallas        | `crimeDataDallasDF`       | `s3://data.intellinum.co/bootcamp/common/crime-data-2016/Crime-Data-Dallas-2016.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY} AWS_SECRET_ACCESS_KEY={AWS_SECRET_KEY} aws s3 ls s3://data.intellinum.co/bootcamp/common/crime-data-2016/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "crimeDataLosAngelesDF = spark.read.parquet(\"s3a://data.intellinum.co/bootcamp/common/crime-data-2016/Crime-Data-Los-Angeles-2016.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimeDataLosAngelesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(crimeDataLosAngelesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "\n",
    "rowsLosAngeles  = crimeDataLosAngelesDF.count()\n",
    "dfTest(\"DF-L7-crimeDataLA-count\", rowsLosAngeles, 217945)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "crimeDataPhiladelphiaDF = spark.read.parquet(\"s3a://data.intellinum.co/bootcamp/common/crime-data-2016/Crime-Data-Philadelphia-2016.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "\n",
    "rowsPhiladelphia  = crimeDataPhiladelphiaDF.count()\n",
    "dfTest(\"DF-L7-crimeDataPA-count\", rowsPhiladelphia, 168664)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "crimeDataDallasDF = spark.read.parquet(\"s3a://data.intellinum.co/bootcamp/common/crime-data-2016/Crime-Data-Dallas-2016.parquet\")\n",
    "crimeDataDallasDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "\n",
    "rowsDallas  = crimeDataDallasDF.count()\n",
    "dfTest(\"DF-L7-crimeDataDAL-count\", 99642, rowsDallas)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "For each table, examine the data to figure out how to extract _robbery_ statistics.\n",
    "\n",
    "Each city uses different values to indicate robbery. Commonly used terminology is \"larceny\", \"burglary\" or \"robbery.\"  These challenges are common in Data Lakes.  These challenges are common in data lakes.  To simplify things, restrict yourself to only the word \"robbery\" (and not attempted-roberty, larceny, or burglary).\n",
    "\n",
    "Explore the data for the three cities until you understand how each city records robbery information. If you don't want to worry about upper- or lower-case, \n",
    "remember to use the DataFrame `lower()` method to converts column values to lowercase.\n",
    "\n",
    "Create a DataFrame containing only the robbery-related rows, as shown in the table below.\n",
    "\n",
    "**Hint:** For each table, focus your efforts on the column listed below.\n",
    "\n",
    "Focus on the following columns for each table:\n",
    "\n",
    "| DataFrame Name            | Robbery DataFrame Name  | Column\n",
    "| ------------------------- | ----------------------- | -------------------------------\n",
    "| `crimeDataLosAngelesDF`   | `robberyLosAngelesDF`   | `crimeCodeDescription`\n",
    "| `crimeDataPhiladelphiaDF` | `robberyPhiladelphiaDF` | `ucr_general_description`\n",
    "| `crimeDataDallasDF`       | `robberyDallasDF`       | `typeOfIncident`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "from pyspark.sql.functions import col, lower\n",
    "robberyLosAngelesDF = crimeDataLosAngelesDF.filter(lower(col(\"crimeCodeDescription\")) == \"robbery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "\n",
    "totalLosAngeles  = robberyLosAngelesDF.count()\n",
    "dfTest(\"DF-L7-robberyDataLA-count\", 9048, totalLosAngeles)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "robberyPhiladelphiaDF  = crimeDataPhiladelphiaDF.filter(lower(col(\"ucr_general_description\")) == \"robbery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "\n",
    "totalPhiladelphia  = robberyPhiladelphiaDF.count()\n",
    "dfTest(\"DF-L7-robberyDataPA-count\", 6149, totalPhiladelphia)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "robberyDallasDF  = crimeDataDallasDF.filter(lower(col(\"typeOfIncident\")).startswith(\"robbery\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "\n",
    "totalDallas = robberyDallasDF.count()\n",
    "dfTest(\"DF-L7-robberyDataDAL-count\", 6824, totalDallas)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "Now that you have DataFrames of only the robberies in each city, create DataFrames for each city summarizing the number of robberies in each month.\n",
    "\n",
    "Your DataFrames must contain two columns:\n",
    "* `month`: The month number (e.g., 1 for January, 2 for February, etc.).\n",
    "* `robberies`: The total number of robberies in the month.\n",
    "\n",
    "Use the following DataFrame names and date columns:\n",
    "\n",
    "\n",
    "| City          | DataFrame Name     | Date Column \n",
    "| ------------- | ------------- | -------------\n",
    "| Los Angeles   | `robberiesByMonthLosAngelesDF` | `timeOccurred`\n",
    "| Philadelphia  | `robberiesByMonthPhiladelphiaDF` | `dispatch_date_time`\n",
    "| Dallas        | `robberiesByMonthDallasDF` | `startingDateTime`\n",
    "\n",
    "For each city, figure out which column contains the date of the incident. Then, extract the month from that date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "from pyspark.sql.functions import month, col, count\n",
    "robberiesByMonthLosAngelesDF = (robberyLosAngelesDF\n",
    "                                .select(month(robberyLosAngelesDF[\"timeOccurred\"]).alias(\"month\"))\n",
    "                                .groupBy(\"month\")\n",
    "                                .agg(count(\"month\").alias(\"robberies\"))\n",
    "                                .orderBy(\"month\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "from pyspark.sql import Row\n",
    "la = list(robberiesByMonthLosAngelesDF.collect())\n",
    "\n",
    "dfTest(\"DF-L7-robberyByMonthLA-counts\", [Row(month=1, robberies=719), Row(month=2, robberies=675), Row(month=3, robberies=709), Row(month=4, robberies=713), Row(month=5, robberies=790), Row(month=6, robberies=698), Row(month=7, robberies=826), Row(month=8, robberies=765), Row(month=9, robberies=722), Row(month=10, robberies=814), Row(month=11, robberies=764), Row(month=12, robberies=853)], la)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "robberiesByMonthPhiladelphiaDF = (robberyPhiladelphiaDF\n",
    "                                 .select(month(robberyPhiladelphiaDF[\"dispatch_date_time\"]).alias(\"month\"))\n",
    "                                 .groupBy(\"month\")\n",
    "                                 .agg(count(\"month\").alias(\"robberies\"))\n",
    "                                 .orderBy(\"month\"))\n",
    "\n",
    "robberiesByMonthPhiladelphiaDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robberyPhiladelphiaDF# TEST - Run this cell to test your solution.\n",
    "# convert to list so that we get deep compare (Array would be a shallow compare)\n",
    "philadelphia  = list(robberiesByMonthPhiladelphiaDF.collect())\n",
    "\n",
    "dfTest(\"DF-L7-robberyByMonthPA-counts\", [Row(month=1, robberies=520), Row(month=2, robberies=416), Row(month=3, robberies=432), Row(month=4, robberies=466), Row(month=5, robberies=533), Row(month=6, robberies=509), Row(month=7, robberies=537), Row(month=8, robberies=561), Row(month=9, robberies=514), Row(month=10, robberies=572), Row(month=11, robberies=545), Row(month=12, robberies=544)], philadelphia )\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "robberiesByMonthDallasDF = (robberyDallasDF \n",
    "                              .select(month(robberyDallasDF[\"startingDateTime\"]).alias(\"month\")) \n",
    "                              .groupBy(\"month\") \n",
    "                              .agg(count(\"month\").alias(\"robberies\"))\n",
    "                              .orderBy(\"month\"))\n",
    "robberiesByMonthDallasDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "\n",
    "dallas  = list(robberiesByMonthDallasDF.collect())\n",
    "dfTest(\"DF-L7-robberyByMonthDAL-counts\", [Row(month=1, robberies=743), Row(month=2, robberies=435), Row(month=3, robberies=412), Row(month=4, robberies=594), Row(month=5, robberies=615), Row(month=6, robberies=495), Row(month=7, robberies=535), Row(month=8, robberies=627), Row(month=9, robberies=512), Row(month=10, robberies=603), Row(month=11, robberies=589), Row(month=12, robberies=664)], dallas)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "Plot the robberies per month for each of the three cities, producing a plot similar to the following:\n",
    "\n",
    "<img src=\"../../resources/robberies-by-month.png\" style=\"max-width: 700px; border: 1px solid #aaaaaa; border-radius: 10px 10px 10px 10px\"/>\n",
    "\n",
    "**Hint:** You may want to use `matplotlib` or `plotly`. If you have your own way of ploting data, feel free to show off here. : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "def plot_cityRobberies(dataframes, cities):\n",
    "    data = []\n",
    "    for i in range(len(dataframes)):\n",
    "        dataframe = dataframes[i]\n",
    "        city = cities[i]\n",
    "        x = go.Bar(\n",
    "                    x = dataframe.toPandas().month,\n",
    "                    y = dataframe.toPandas().robberies,\n",
    "                    name = city,\n",
    "                )\n",
    "        data.append(x)\n",
    "\n",
    "    if len(cities) < 2:\n",
    "        title = cities[0]\n",
    "    else:\n",
    "        title = \"Cities\"\n",
    "    layout = go.Layout(\n",
    "                title=\"Robberies/month in \"+str(title),\n",
    "                xaxis={\n",
    "                    \"title\" : \"Month\",\n",
    "                    \"tickfont\" : {\n",
    "                        \"size\" : 14,\n",
    "                    }\n",
    "                },\n",
    "                yaxis={\n",
    "                    \"title\" : \"Robberies (Count)\",\n",
    "                    \"tickfont\" : {\n",
    "                        \"size\" : 10,\n",
    "                    }\n",
    "                },\n",
    "                legend = {\n",
    "                    \"x\" : 1,\n",
    "                    \"y\" : 1\n",
    "                },\n",
    "                barmode=\"group\",\n",
    "                bargap=0.15,\n",
    "                bargroupgap=0.1\n",
    "            )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_cityRobberies([robberiesByMonthLosAngelesDF], [\"LA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "plot_cityRobberies([robberiesByMonthPhiladelphiaDF], [\"PA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "plot_cityRobberies([robberiesByMonthDallasDF], [\"Dallas\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All three Cities side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityDataframesList = [robberiesByMonthDallasDF, robberiesByMonthLosAngelesDF, robberiesByMonthPhiladelphiaDF]\n",
    "cityList = [\"Los Angeles\", \"Philadelphia\", \"Dallas\"]\n",
    "plot_cityRobberies(cityDataframesList, cityList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "\n",
    "Create another DataFrame called `combinedRobberiesByMonthDF`, that combines all three robberies-per-month views into one.\n",
    "In creating this view, add a new column called `city`, that identifies the city associated with each row.\n",
    "The final view will have the following columns:\n",
    "\n",
    "* `city`: The name of the city associated with the row. (Use the strings \"Los Angeles\", \"Philadelphia\", and \"Dallas\".)\n",
    "* `month`: The month number associated with the row.\n",
    "* `robbery`: The number of robbery in that month (for that city).\n",
    "\n",
    "**Hint:** You may want to apply the `union()` method in this example to combine the three datasets.\n",
    "\n",
    "**Hint:** It's easy to add new columns in DataFrames. For example, add a new column called `newColumn` to `originalDF` use `withColumn()` method as follows:\n",
    "\n",
    "```originalDF.withColumn(\"newColumn\")``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "from pyspark.sql.functions import lit, desc, asc\n",
    "\n",
    "combinedRobberiesByMonthDF = (robberiesByMonthLosAngelesDF.withColumn(\"city\", lit(\"Los Angeles\")).select(\"*\")\n",
    "                            .union(robberiesByMonthPhiladelphiaDF.withColumn(\"city\", lit(\"Philadelphia\")).select(\"*\"))\n",
    "                            .union(robberiesByMonthDallasDF.withColumn(\"city\", lit(\"Dallas\")).select(\"*\"))\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedRobberiesByMonthDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(combinedRobberiesByMonthDF, 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "\n",
    "results = [ (r.city, r.month, r.robberies) for r in combinedRobberiesByMonthDF.collect() ]\n",
    "expectedResults =  [ \n",
    "(u'Los Angeles', 1, 719), \n",
    "(u'Los Angeles', 2, 675), \n",
    "(u'Los Angeles', 3, 709), \n",
    "(u'Los Angeles', 4, 713),   \n",
    "(u'Los Angeles', 5, 790), \n",
    "(u'Los Angeles', 6, 698), \n",
    "(u'Los Angeles', 7, 826), \n",
    "(u'Los Angeles', 8, 765), \n",
    "(u'Los Angeles', 9, 722), \n",
    "(u'Los Angeles', 10, 814), \n",
    "(u'Los Angeles', 11, 764), \n",
    "(u'Los Angeles', 12, 853), \n",
    "(u'Philadelphia', 1, 520), \n",
    "(u'Philadelphia', 2, 416), \n",
    "(u'Philadelphia', 3, 432), \n",
    "(u'Philadelphia', 4, 466),\n",
    "(u'Philadelphia', 5, 533), \n",
    "(u'Philadelphia', 6, 509), \n",
    "(u'Philadelphia', 7, 537), \n",
    "(u'Philadelphia', 8, 561), \n",
    "(u'Philadelphia', 9, 514), \n",
    "(u'Philadelphia', 10, 572), \n",
    "(u'Philadelphia', 11, 545), \n",
    "(u'Philadelphia', 12, 544), \n",
    "(u'Dallas', 1, 743),\n",
    "(u'Dallas', 2, 435), \n",
    "(u'Dallas', 3, 412), \n",
    "(u'Dallas', 4, 594), \n",
    "(u'Dallas', 5, 615), \n",
    "(u'Dallas', 6, 495), \n",
    "(u'Dallas', 7, 535), \n",
    "(u'Dallas', 8, 627), \n",
    "(u'Dallas', 9, 512), \n",
    "(u'Dallas', 10, 603), \n",
    "(u'Dallas', 11, 589), \n",
    "(u'Dallas', 12, 664)] \n",
    "\n",
    "dfTest(\"DF-L7-combinedRobberiesByMonth-counts\", expectedResults, results)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6\n",
    "\n",
    "Graph the contents of `combinedRobberiesByMonthDF`, producing a graph similar to the following. (The diagram below deliberately\n",
    "uses different data.)\n",
    "\n",
    "<img src=\"../../resources/combined-homicides.png\" style=\"width: 800px; border: 1px solid #aaaaaa; border-radius: 10px 10px 10px 10px\"/>\n",
    "\n",
    "**Hint:** Order your results by `month`, then `city`.\n",
    "\n",
    "**Hint:** You may want to use `matplotlib` or `plotly`. If you have your own way of ploting data, feel free to show off here. : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "display(combinedRobberiesByMonthDF.orderBy(\"month\", \"city\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [go.Bar(x=subset.month, \n",
    "                 y=subset.robberies,\n",
    "                 name=city) \n",
    "          for city, subset in combinedRobberiesByMonthDF.toPandas().groupby(\"city\")]\n",
    "\n",
    "layout = go.Layout(\n",
    "            title=\"Robberies/month\",\n",
    "            xaxis={\n",
    "                \"title\" : \"Month\",\n",
    "                \"tickfont\" : {\n",
    "                    \"size\" : 14,\n",
    "                }\n",
    "            },\n",
    "            yaxis={\n",
    "                \"title\" : \"Robberies (Count)\",\n",
    "                \"tickfont\" : {\n",
    "                    \"size\" : 10,\n",
    "                }\n",
    "            },\n",
    "            legend = {\n",
    "                \"x\" : 1,\n",
    "                \"y\" : 1\n",
    "            },\n",
    "            barmode=\"group\",\n",
    "            bargap=0.15,\n",
    "            bargroupgap=0.1\n",
    "        )\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "plotly.offline.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7\n",
    "\n",
    "While the above graph is interesting, it's flawed: it's comparing the raw numbers of robberies, not the per capita robbery rates.\n",
    "\n",
    "The DataFrame (already created) called `cityDataDF`  contains, among other data, estimated 2016 population values for all United States cities\n",
    "with populations of at least 100,000. (The data is from [Wikipedia](https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population).)\n",
    "\n",
    "* Use the population values in that table to normalize the robberies so they represent per-capita values (total robberies divided by population).\n",
    "* Save your results in a DataFrame called `robberyRatesByCityDF`.\n",
    "* The robbery rate value must be stored in a new column, `robberyRate`.\n",
    "\n",
    "Next, graph the results, as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedRobberiesByMonthDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(combinedRobberiesByMonthDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityDataDF = spark.read.parquet(\"s3://data.intellinum.co/bootcamp/common/City-Data.parquet\").withColumnRenamed(\"city\", \"cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityDataDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cityDataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robberyRatesByCityDF = (combinedRobberiesByMonthDF.select(\"month\", \"robberies\", \"city\")\n",
    "                           .join(cityDataDF, cityDataDF.cities == combinedRobberiesByMonthDF.city)\n",
    "                           .withColumn(\"robberyRate\", col('robberies')/col('estPopulation2016')))\n",
    "\n",
    "robberyRatesByCityDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [go.Bar(x=subset.month, \n",
    "                 y=subset.robberyRate,\n",
    "                 name=city) \n",
    "          for city, subset in robberyRatesByCityDF.toPandas().groupby(\"city\")]\n",
    "\n",
    "layout = go.Layout(\n",
    "            title=\"Robbery Rate/month\",\n",
    "            xaxis={\n",
    "                \"title\" : \"Month\",\n",
    "                \"tickfont\" : {\n",
    "                    \"size\" : 14,\n",
    "                }\n",
    "            },\n",
    "            yaxis={\n",
    "                \"title\" : \"Robbery Rate\",\n",
    "                \"tickfont\" : {\n",
    "                    \"size\" : 10,\n",
    "                }\n",
    "            },\n",
    "            legend = {\n",
    "                \"x\" : 1,\n",
    "                \"y\" : 1\n",
    "            },\n",
    "            barmode=\"group\",\n",
    "            bargap=0.15,\n",
    "            bargroupgap=0.1\n",
    "        )\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "plotly.offline.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "results = [ (r.city, r.month, '{:6f}'.format(r.robberyRate)) for r in robberyRatesByCityDF.orderBy(\"city\", \"month\").collect() ]\n",
    "expectedResults = [\n",
    "  (u'Dallas',  1, '0.000564'),\n",
    "  (u'Dallas',  2, '0.000330'),\n",
    "  (u'Dallas',  3, '0.000313'),\n",
    "  (u'Dallas',  4, '0.000451'),\n",
    "  (u'Dallas',  5, '0.000467'),\n",
    "  (u'Dallas',  6, '0.000376'),\n",
    "  (u'Dallas',  7, '0.000406'),\n",
    "  (u'Dallas',  8, '0.000476'),\n",
    "  (u'Dallas',  9, '0.000388'),\n",
    "  (u'Dallas', 10, '0.000458'),\n",
    "  (u'Dallas', 11, '0.000447'),\n",
    "  (u'Dallas', 12, '0.000504'),\n",
    "  (u'Los Angeles',  1, '0.000181'),\n",
    "  (u'Los Angeles',  2, '0.000170'),\n",
    "  (u'Los Angeles',  3, '0.000178'),\n",
    "  (u'Los Angeles',  4, '0.000179'),\n",
    "  (u'Los Angeles',  5, '0.000199'),\n",
    "  (u'Los Angeles',  6, '0.000176'),\n",
    "  (u'Los Angeles',  7, '0.000208'),\n",
    "  (u'Los Angeles',  8, '0.000192'),\n",
    "  (u'Los Angeles',  9, '0.000182'),\n",
    "  (u'Los Angeles', 10, '0.000205'),\n",
    "  (u'Los Angeles', 11, '0.000192'),\n",
    "  (u'Los Angeles', 12, '0.000215'),\n",
    "  (u'Philadelphia',  1, '0.000332'),\n",
    "  (u'Philadelphia',  2, '0.000265'),\n",
    "  (u'Philadelphia',  3, '0.000276'),\n",
    "  (u'Philadelphia',  4, '0.000297'),\n",
    "  (u'Philadelphia',  5, '0.000340'),\n",
    "  (u'Philadelphia',  6, '0.000325'),\n",
    "  (u'Philadelphia',  7, '0.000343'),\n",
    "  (u'Philadelphia',  8, '0.000358'),\n",
    "  (u'Philadelphia',  9, '0.000328'),\n",
    "  (u'Philadelphia', 10, '0.000365'),\n",
    "  (u'Philadelphia', 11, '0.000348'),\n",
    "  (u'Philadelphia', 12, '0.000347')]\n",
    "dfTest(\"DF-L7-roberryRatesByCity-counts\", expectedResults, results)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Congratulation! You have just finished the `pyspark` section of `DE-200` course. Before you move on to the next course (`DE-210: ETL Part 1: Data Extraction`), let's learn writing spark code in Scala! And I will make this fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "Zeppelin is the BEST open-source jvm-based interactive notebook environment. We'll be using Zeppelin for this part of the excercise. Bye, Jupyter!\n",
    "\n",
    "You can find the Zeppelin endpoint url in this [Trello card](https://trello.com/c/LptF6oaI/13-lab-environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "Once you're there, please take a look at Zeppelin Tutorial first.\n",
    "\n",
    "<img src=\"../../resources/zeppelin-tutorial-3.png\" style=\"width: 800px; border: 1px solid #aaaaaa; border-radius: 10px 10px 10px 10px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "Next, take a look at the template notebook in my workspace. You should create the same notebook in your own workspace.\n",
    "\n",
    "<img src=\"../../resources/zeppelin-tutorial-1.png\" style=\"width: 800px; border: 1px solid #aaaaaa; border-radius: 10px 10px 10px 10px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "It's super easy to create visualization in Zeppelin. \n",
    "\n",
    "<img src=\"../../resources/zeppelin-tutorial-2.png\" style=\"width: 800px; border: 1px solid #aaaaaa; border-radius: 10px 10px 10px 10px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "\n",
    "You're all set. Please go ahead and rewrite this project in scala and visualize your results in Zeppelin. If you want to learn more about Zeppelin, take a look at these links. I'll cover these topics in greater details in the future courses.\n",
    "- https://zeppelin.apache.org/docs/0.8.1/quickstart/explore_ui.html\n",
    "- https://zeppelin.apache.org/docs/0.8.1/quickstart/tutorial.html\n",
    "- https://zeppelin.apache.org/docs/0.8.1/quickstart/spark_with_zeppelin.html\n",
    "- https://zeppelin.apache.org/docs/0.8.1/setup/deployment/spark_cluster_mode.html#spark-on-mesos-mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "The crime data used in this notebook comes from the following locations:\n",
    "\n",
    "| City          | Original Data \n",
    "| ------------- | -------------\n",
    "| Boston        | <a href=\"https://data.boston.gov/group/public-safety\" target=\"_blank\">https&#58;//data.boston.gov/group/public-safety</a>\n",
    "| Chicago       | <a href=\"https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2\" target=\"_blank\">https&#58;//data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2</a>\n",
    "| Dallas        | <a href=\"https://www.dallasopendata.com/Public-Safety/Police-Incidents/tbnj-w5hb/data\" target=\"_blank\">https&#58;//www.dallasopendata.com/Public-Safety/Police-Incidents/tbnj-w5hb/data</a>\n",
    "| Los Angeles   | <a href=\"https://data.lacity.org/A-Safe-City/Crime-Data-From-2010-to-Present/y8tr-7khq\" target=\"_blank\">https&#58;//data.lacity.org/A-Safe-City/Crime-Data-From-2010-to-Present/y8tr-7khq</a>\n",
    "| New Orleans   | <a href=\"https://data.nola.gov/Public-Safety-and-Preparedness/Electronic-Police-Report-2016/4gc2-25he/data\" target=\"_blank\">https&#58;//data.nola.gov/Public-Safety-and-Preparedness/Electronic-Police-Report-2016/4gc2-25he/data</a>\n",
    "| New York      | <a href=\"https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i\" target=\"_blank\">https&#58;//data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i</a>\n",
    "| Philadelphia  | <a href=\"https://www.opendataphilly.org/dataset/crime-incidents\" target=\"_blank\">https&#58;//www.opendataphilly.org/dataset/crime-incidents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy; 2019 [Intellinum Analytics, Inc](http://www.intellinum.co). All rights reserved.<br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark24_py36]",
   "language": "python",
   "name": "conda-env-pyspark24_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
