{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"../../resources/logo.png\" alt=\"Intellinum Bootcamp\" style=\"width: 400px; height: 200px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "\n",
    "Apache Spark&trade; allow you to use DataFrames to query large data files.\n",
    "\n",
    "## In this lesson you:\n",
    "* Learn about Spark DataFrames.\n",
    "* Query large files using Spark DataFrames.\n",
    "* Visualize query results using charts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing DataFrames\n",
    "\n",
    "Under the covers, DataFrames are derived from data structures known as Resilient Distributed Datasets (RDDs). RDDs and DataFrames are immutable distributed collections of data. Let's take a closer look at what some of these terms mean before we understand how they relate to DataFrames:\n",
    "\n",
    "* **Resilient**: They are fault tolerant, so if part of your operation fails, Spark  quickly recovers the lost computation.\n",
    "* **Distributed**: RDDs are distributed across networked machines known as a cluster.\n",
    "* **DataFrame**: A data structure where data is organized into named columns, like a table in a relational database, but with richer optimizations under the hood. \n",
    "\n",
    "Without the named columns and declared types provided by a schema, Spark wouldn't know how to optimize the executation of any computation. Since DataFrames have a schema, they use the Catalyst Optimizer to determine the optimal way to execute your code.\n",
    "\n",
    "* **Catalyst Optimizer**: Spark SQL is one of the newest and most technically involved components of Spark. It powers both SQL queries and the new DataFrame API. At the core of Spark SQL is the Catalyst optimizer, which leverages advanced programming language features (e.g. Scala’s pattern matching and quasiquotes) in a novel way to build an extensible query optimizer. To implement Spark SQL, a new extensible optimizer, Catalyst was designed, based on functional programming constructs in Scala. Catalyst’s extensible design had two purposes. First, we wanted to make it easy to add new optimization techniques and features to Spark SQL, especially for the purpose of tackling various problems we were seeing with big data (e.g., semistructured data and advanced analytics). Second, we wanted to enable external developers to extend the optimizer — for example, by adding data source specific rules that can push filtering or aggregation into external storage systems, or support for new data types. Catalyst supports both rule-based and cost-based optimization.\n",
    "\n",
    "\n",
    "DataFrames were invented because the business community uses tables in a relational database, Pandas or R DataFrames, or Excel worksheets. A Spark DataFrame is conceptually equivalent to these, with richer optimizations under the hood and the benefit of being distributed across a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interacting with DataFrames\n",
    "\n",
    "Once created (instantiated), a DataFrame object has methods attached to it. Methods are operations one can perform on DataFrames such as filtering,\n",
    "counting, aggregating and many others.\n",
    "\n",
    "> <b>Example</b>: To create (instantiate) a DataFrame, use this syntax: `df = ...`\n",
    "\n",
    "To display the contents of the DataFrame, apply a `show` operation (method) on it using the syntax `df.show()`. \n",
    "\n",
    "The `.` indicates you are *applying a method on the object*.\n",
    "\n",
    "In working with DataFrames, it is common to chain operations together, such as: `df.select().filter().orderBy()`.  \n",
    "\n",
    "By chaining operations together, you don't need to save intermediate DataFrames into local variables (thereby avoiding the creation of extra objects).\n",
    "\n",
    "**Also note that you do not have to worry about how to order operations because the optimizier determines the optimal order of execution of the operations for you.**\n",
    "\n",
    "`df.select(...).orderBy(...).filter(...)`\n",
    "\n",
    "versus\n",
    "\n",
    "`df.filter(...).select(...).orderBy(...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrames and SQL\n",
    "\n",
    "DataFrame syntax is more flexible than SQL syntax. Here we illustrate general usage patterns of SQL and DataFrames.\n",
    "\n",
    "Suppose we have a data set we loaded as a table called `myTable` and an equivalent DataFrame, called `df`.\n",
    "We have three fields/columns called `col_1` (numeric type), `col_2` (string type) and `col_3` (timestamp type)\n",
    "Here are basic SQL operations and their DataFrame equivalents. \n",
    "\n",
    "Notice that columns in DataFrames are referenced by `col(\"<columnName>\")`.\n",
    "\n",
    "| SQL                                         | DataFrame (Python)                    |\n",
    "| ------------------------------------------- | ------------------------------------- | \n",
    "| `SELECT col_1 FROM myTable`                 | `df.select(col(\"col_1\"))`             | \n",
    "| `DESCRIBE myTable`                          | `df.printSchema()`                    | \n",
    "| `SELECT * FROM myTable WHERE col_1 > 0`     | `df.filter(col(\"col_1\") > 0)`         | \n",
    "| `..GROUP BY col_2`                          | `..groupBy(col(\"col_2\"))`             | \n",
    "| `..ORDER BY col_2`                          | `..orderBy(col(\"col_2\"))`             | \n",
    "| `..WHERE year(col_3) > 1990`                | `..filter(year(col(\"col_3\")) > 1990)` | \n",
    "| `SELECT * FROM myTable LIMIT 10`            | `df.limit(10)`                        |\n",
    "| `display(myTable)` (text format)            | `df.show()`                           | \n",
    "| `display(myTable)` (html format)            | `display(df)`                         |\n",
    "\n",
    "**Hint:** You can also run SQL queries with the special syntax `spark.sql(\"SELECT * FROM myTable\")`\n",
    "\n",
    "In this course you see many other usages of DataFrames. It is left up to you to figure out the SQL equivalents \n",
    "(left as exercises in some cases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Spark context\n",
    "First thing first, let's create the sparkContext, if you don't understand this part, don't worry. We'll cover this in greater details in future lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing SparkSession\n"
     ]
    }
   ],
   "source": [
    "#MODE = \"LOCAL\"\n",
    "MODE = \"CLUSTER\"\n",
    "\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from matplotlib import interactive\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "interactive(True)\n",
    "import json\n",
    "import math\n",
    "import numbers\n",
    "import numpy as np\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "sys.path.insert(0,'../../src')\n",
    "from settings import *\n",
    "\n",
    "try:\n",
    "    fh = open('../../libs/pyspark24_py36.zip', 'r')\n",
    "except FileNotFoundError:\n",
    "    !AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY} AWS_SECRET_ACCESS_KEY={AWS_SECRET_KEY} aws s3 cp s3://yuan.intellinum.co/bins/pyspark24_py36.zip ../../libs/pyspark24_py36.zip\n",
    "\n",
    "try:\n",
    "    spark.stop()\n",
    "    print(\"Stopped a SparkSession\")\n",
    "except Exception as e:\n",
    "    print(\"No existing SparkSession\")\n",
    "\n",
    "SPARK_DRIVER_MEMORY= \"2G\"\n",
    "SPARK_DRIVER_CORE = \"1\"\n",
    "SPARK_EXECUTOR_MEMORY= \"1G\"\n",
    "SPARK_EXECUTOR_CORE = \"1\"\n",
    "SPARK_EXECUTOR_INSTANCES = 6\n",
    "\n",
    "\n",
    "\n",
    "conf = None\n",
    "if MODE == \"LOCAL\":\n",
    "    os.environ[\"PYSPARK_PYTHON\"] = \"/home/yuan/anaconda3/envs/pyspark24_py36/bin/python\"\n",
    "    conf = SparkConf().\\\n",
    "            setAppName(\"pyspark_day01_dataframe\").\\\n",
    "            setMaster('local[*]').\\\n",
    "            set('spark.driver.maxResultSize', '0').\\\n",
    "            set('spark.jars', '../../libs/mysql-connector-java-5.1.45-bin.jar').\\\n",
    "            set('spark.jars.packages','net.java.dev.jets3t:jets3t:0.9.0,com.google.guava:guava:16.0.1,com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.1')\n",
    "else:\n",
    "    os.environ[\"PYSPARK_PYTHON\"] = \"./MN/pyspark24_py36/bin/python\"\n",
    "    conf = SparkConf().\\\n",
    "            setAppName(\"pyspark_day01_dataframe\").\\\n",
    "            setMaster('yarn-client').\\\n",
    "            set('spark.executor.cores', SPARK_EXECUTOR_CORE).\\\n",
    "            set('spark.executor.memory', SPARK_EXECUTOR_MEMORY).\\\n",
    "            set('spark.driver.cores', SPARK_DRIVER_CORE).\\\n",
    "            set('spark.driver.memory', SPARK_DRIVER_MEMORY).\\\n",
    "            set(\"spark.executor.instances\", SPARK_EXECUTOR_INSTANCES).\\\n",
    "            set('spark.sql.files.ignoreCorruptFiles', 'true').\\\n",
    "            set('spark.yarn.dist.archives', '../../libs/pyspark24_py36.zip#MN').\\\n",
    "            set('spark.sql.shuffle.partitions', '5000').\\\n",
    "            set('spark.default.parallelism', '5000').\\\n",
    "            set('spark.driver.maxResultSize', '0').\\\n",
    "            set('spark.jars.packages','net.java.dev.jets3t:jets3t:0.9.0,com.google.guava:guava:16.0.1,com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.1'). \\\n",
    "            set('spark.driver.maxResultSize', '0').\\\n",
    "            set('spark.jars', 's3://yuan.intellinum.co/bins/mysql-connector-java-5.1.45-bin.jar')\n",
    "        \n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "    config(conf=conf).\\\n",
    "    getOrCreate()\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc.addPyFile('../../src/settings.py')\n",
    "\n",
    "sc=spark.sparkContext\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "hadoop_conf.set(\"fs.s3a.access.key\", AWS_ACCESS_KEY)\n",
    "hadoop_conf.set(\"fs.s3a.secret.key\", AWS_SECRET_KEY)\n",
    "hadoop_conf.set(\"mapreduce.fileoutputcommitter.algorithm.version\", \"2\")\n",
    "\n",
    "def display(df, limit=10):\n",
    "    return df.limit(limit).toPandas()\n",
    "\n",
    "def dfTest(id, expected, result):\n",
    "    assert str(expected) == str(result), \"{} does not equal expected {}\".format(result, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Data \n",
    "This lesson uses the `people-10m` data set, which is in Parquet format.\n",
    "\n",
    "The data is fictitious; in particular, the Social Security numbers are fake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command below to see the contents of the `people-10m.parquet` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 19:00:58          0 _SUCCESS\n",
      "2019-05-29 19:00:44    8118248 part-00000-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:42    8118593 part-00001-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:44    8118640 part-00002-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:44    8118248 part-00003-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:42    8118843 part-00004-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:43    8118583 part-00005-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:43    8118249 part-00006-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:42    8119267 part-00007-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:42    8118869 part-00008-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:44    8118167 part-00009-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:44    8118062 part-00010-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:44    8119815 part-00011-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:44    8118994 part-00012-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:44    8117773 part-00013-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:43    8118589 part-00014-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:42    8119498 part-00015-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:44    8119482 part-00016-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:44    8118946 part-00017-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:42    8119250 part-00018-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:44    8118181 part-00019-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:44    8118779 part-00020-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:45    8117520 part-00021-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:42    8119569 part-00022-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:54    8118023 part-00023-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:52    8118527 part-00024-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:52    8119218 part-00025-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:52    8118569 part-00026-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:52    8118883 part-00027-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:53    8119203 part-00028-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n",
      "2019-05-29 19:00:53    8117925 part-00029-e69f0106-f446-443c-9049-d95493afe9a5-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY} AWS_SECRET_ACCESS_KEY={AWS_SECRET_KEY} aws s3 ls s3://data.intellinum.co/bootcamp/common/people-10m.parquet/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "peopleDF = spark.read.parquet(\"s3a://data.intellinum.co/bootcamp/common/people-10m.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>firstName</th>\n",
       "      <th>middleName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>ssn</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>838880</td>\n",
       "      <td>Margarete</td>\n",
       "      <td>Willetta</td>\n",
       "      <td>Shearwood</td>\n",
       "      <td>F</td>\n",
       "      <td>1997-03-24 05:00:00</td>\n",
       "      <td>961-82-3018</td>\n",
       "      <td>74468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>828908</td>\n",
       "      <td>Almeda</td>\n",
       "      <td>Un</td>\n",
       "      <td>Standring</td>\n",
       "      <td>F</td>\n",
       "      <td>1969-10-31 05:00:00</td>\n",
       "      <td>925-45-8150</td>\n",
       "      <td>55688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842059</td>\n",
       "      <td>Launa</td>\n",
       "      <td>Jamie</td>\n",
       "      <td>Carling</td>\n",
       "      <td>F</td>\n",
       "      <td>1978-12-25 05:00:00</td>\n",
       "      <td>906-73-9805</td>\n",
       "      <td>92511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>812971</td>\n",
       "      <td>Allie</td>\n",
       "      <td>Marlin</td>\n",
       "      <td>Guye</td>\n",
       "      <td>F</td>\n",
       "      <td>1986-12-02 05:00:00</td>\n",
       "      <td>934-31-9535</td>\n",
       "      <td>48451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>802482</td>\n",
       "      <td>Anamaria</td>\n",
       "      <td>Keren</td>\n",
       "      <td>Benjefield</td>\n",
       "      <td>F</td>\n",
       "      <td>1982-08-10 04:00:00</td>\n",
       "      <td>999-45-4193</td>\n",
       "      <td>90330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>811453</td>\n",
       "      <td>Fay</td>\n",
       "      <td>Ethyl</td>\n",
       "      <td>Charrisson</td>\n",
       "      <td>F</td>\n",
       "      <td>1996-12-30 05:00:00</td>\n",
       "      <td>942-57-6945</td>\n",
       "      <td>84103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>816555</td>\n",
       "      <td>Estela</td>\n",
       "      <td>Cathy</td>\n",
       "      <td>Cleveley</td>\n",
       "      <td>F</td>\n",
       "      <td>1958-03-08 05:00:00</td>\n",
       "      <td>976-50-7231</td>\n",
       "      <td>54632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>829473</td>\n",
       "      <td>Akilah</td>\n",
       "      <td>Leola</td>\n",
       "      <td>Grier</td>\n",
       "      <td>F</td>\n",
       "      <td>1995-01-04 05:00:00</td>\n",
       "      <td>941-54-1418</td>\n",
       "      <td>63966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  firstName middleName    lastName gender           birthDate  \\\n",
       "0  838880  Margarete   Willetta   Shearwood      F 1997-03-24 05:00:00   \n",
       "1  828908     Almeda         Un   Standring      F 1969-10-31 05:00:00   \n",
       "2  842059      Launa      Jamie     Carling      F 1978-12-25 05:00:00   \n",
       "3  812971      Allie     Marlin        Guye      F 1986-12-02 05:00:00   \n",
       "4  802482   Anamaria      Keren  Benjefield      F 1982-08-10 04:00:00   \n",
       "5  811453        Fay      Ethyl  Charrisson      F 1996-12-30 05:00:00   \n",
       "6  816555     Estela      Cathy    Cleveley      F 1958-03-08 05:00:00   \n",
       "7  829473     Akilah      Leola       Grier      F 1995-01-04 05:00:00   \n",
       "\n",
       "           ssn  salary  \n",
       "0  961-82-3018   74468  \n",
       "1  925-45-8150   55688  \n",
       "2  906-73-9805   92511  \n",
       "3  934-31-9535   48451  \n",
       "4  999-45-4193   90330  \n",
       "5  942-57-6945   84103  \n",
       "6  976-50-7231   54632  \n",
       "7  941-54-1418   63966  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(peopleDF, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the schema with the `printSchema` method. This tells you the field name, field type, and whether the column is nullable or not (default is true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- middleName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- birthDate: timestamp (nullable = true)\n",
      " |-- ssn: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following question:\n",
    "> According to our data, which women were born after 1990?\n",
    "\n",
    "Use the DataFrame `select` and `filter` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstName</th>\n",
       "      <th>middleName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Margarete</td>\n",
       "      <td>Willetta</td>\n",
       "      <td>Shearwood</td>\n",
       "      <td>1997-03-24 05:00:00</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fay</td>\n",
       "      <td>Ethyl</td>\n",
       "      <td>Charrisson</td>\n",
       "      <td>1996-12-30 05:00:00</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akilah</td>\n",
       "      <td>Leola</td>\n",
       "      <td>Grier</td>\n",
       "      <td>1995-01-04 05:00:00</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jannie</td>\n",
       "      <td>Arlean</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>1995-09-05 04:00:00</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evita</td>\n",
       "      <td>Heidi</td>\n",
       "      <td>Mears</td>\n",
       "      <td>1994-10-30 04:00:00</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Williemae</td>\n",
       "      <td>Claudia</td>\n",
       "      <td>Crowley</td>\n",
       "      <td>1996-09-29 04:00:00</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Evelina</td>\n",
       "      <td>Yee</td>\n",
       "      <td>Bucklan</td>\n",
       "      <td>1994-02-15 05:00:00</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oralia</td>\n",
       "      <td>Lyndsay</td>\n",
       "      <td>Patnelli</td>\n",
       "      <td>1995-12-13 05:00:00</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pasty</td>\n",
       "      <td>Marlana</td>\n",
       "      <td>Gresser</td>\n",
       "      <td>1994-01-09 05:00:00</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tangela</td>\n",
       "      <td>Marin</td>\n",
       "      <td>Mawne</td>\n",
       "      <td>1997-11-05 05:00:00</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstName middleName    lastName           birthDate gender\n",
       "0  Margarete   Willetta   Shearwood 1997-03-24 05:00:00      F\n",
       "1        Fay      Ethyl  Charrisson 1996-12-30 05:00:00      F\n",
       "2     Akilah      Leola       Grier 1995-01-04 05:00:00      F\n",
       "3     Jannie     Arlean       Aaron 1995-09-05 04:00:00      F\n",
       "4      Evita      Heidi       Mears 1994-10-30 04:00:00      F\n",
       "5  Williemae    Claudia     Crowley 1996-09-29 04:00:00      F\n",
       "6    Evelina        Yee     Bucklan 1994-02-15 05:00:00      F\n",
       "7     Oralia    Lyndsay    Patnelli 1995-12-13 05:00:00      F\n",
       "8      Pasty    Marlana     Gresser 1994-01-09 05:00:00      F\n",
       "9    Tangela      Marin       Mawne 1997-11-05 05:00:00      F"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "display(\n",
    "  peopleDF \n",
    "    .select(\"firstName\",\"middleName\",\"lastName\",\"birthDate\",\"gender\") \n",
    "    .filter(\"gender = 'F'\") \n",
    "    .filter(year(\"birthDate\") > \"1990\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-In Functions\n",
    "\n",
    "Spark provides a number of <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\" target=\"_blank\">built-in functions</a>, many of which can be used directly with DataFrames.  Use these functions in the `filter` expressions to filter data and in `select` expressions to create derived columns.\n",
    "\n",
    "The following DataFrame statement finds women born after 1990; it uses the `year` function, and it creates a `birthYear` column on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstName</th>\n",
       "      <th>middleName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Margarete</td>\n",
       "      <td>Willetta</td>\n",
       "      <td>Shearwood</td>\n",
       "      <td>1997</td>\n",
       "      <td>74468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fay</td>\n",
       "      <td>Ethyl</td>\n",
       "      <td>Charrisson</td>\n",
       "      <td>1996</td>\n",
       "      <td>84103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akilah</td>\n",
       "      <td>Leola</td>\n",
       "      <td>Grier</td>\n",
       "      <td>1995</td>\n",
       "      <td>63966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jannie</td>\n",
       "      <td>Arlean</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>1995</td>\n",
       "      <td>95509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evita</td>\n",
       "      <td>Heidi</td>\n",
       "      <td>Mears</td>\n",
       "      <td>1994</td>\n",
       "      <td>96999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Williemae</td>\n",
       "      <td>Claudia</td>\n",
       "      <td>Crowley</td>\n",
       "      <td>1996</td>\n",
       "      <td>77500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Evelina</td>\n",
       "      <td>Yee</td>\n",
       "      <td>Bucklan</td>\n",
       "      <td>1994</td>\n",
       "      <td>73325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oralia</td>\n",
       "      <td>Lyndsay</td>\n",
       "      <td>Patnelli</td>\n",
       "      <td>1995</td>\n",
       "      <td>57709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pasty</td>\n",
       "      <td>Marlana</td>\n",
       "      <td>Gresser</td>\n",
       "      <td>1994</td>\n",
       "      <td>53642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tangela</td>\n",
       "      <td>Marin</td>\n",
       "      <td>Mawne</td>\n",
       "      <td>1997</td>\n",
       "      <td>83712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstName middleName    lastName  birthYear  salary\n",
       "0  Margarete   Willetta   Shearwood       1997   74468\n",
       "1        Fay      Ethyl  Charrisson       1996   84103\n",
       "2     Akilah      Leola       Grier       1995   63966\n",
       "3     Jannie     Arlean       Aaron       1995   95509\n",
       "4      Evita      Heidi       Mears       1994   96999\n",
       "5  Williemae    Claudia     Crowley       1996   77500\n",
       "6    Evelina        Yee     Bucklan       1994   73325\n",
       "7     Oralia    Lyndsay    Patnelli       1995   57709\n",
       "8      Pasty    Marlana     Gresser       1994   53642\n",
       "9    Tangela      Marin       Mawne       1997   83712"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(\n",
    "  peopleDF.select(\"firstName\",\n",
    "                  \"middleName\",\n",
    "                  \"lastName\",\n",
    "                  year(\"birthDate\").alias('birthYear'),\n",
    "                  \"salary\") \n",
    "    .filter(year(\"birthDate\") > \"1990\") \n",
    "    .filter(\"gender = 'F' \")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "In this section, you'll learn how to visualize your spark dataframe using matplotlib and plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many women were named Mary in each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "marysDF = (peopleDF.select(year(\"birthDate\").alias(\"birthYear\")) \n",
    "  .filter(\"firstName = 'Mary' \") \n",
    "  .filter(\"gender = 'F' \") \n",
    "  .orderBy(\"birthYear\") \n",
    "  .groupBy(\"birthYear\") \n",
    "  .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birthYear</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1952</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1953</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1954</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1955</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1957</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1958</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1959</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1960</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1961</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1962</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1963</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1964</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1965</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1966</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1967</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1968</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1969</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1970</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1971</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    birthYear  count\n",
       "0        1952     27\n",
       "1        1953     25\n",
       "2        1954     15\n",
       "3        1955     23\n",
       "4        1956     28\n",
       "5        1957     29\n",
       "6        1958     26\n",
       "7        1959     28\n",
       "8        1960     37\n",
       "9        1961     29\n",
       "10       1962     15\n",
       "11       1963     27\n",
       "12       1964     24\n",
       "13       1965     18\n",
       "14       1966     27\n",
       "15       1967     28\n",
       "16       1968     24\n",
       "17       1969     32\n",
       "18       1970     31\n",
       "19       1971     15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(marysDF,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the visualization process, we first create the dataset for Plotly from the spark dataframe and then call `plotly.offline.iplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "marys_pandas_DF = marysDF.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__matplotlib__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(marys_pandas_DF['birthYear'], color='#86bf91')\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__plotly__\n",
    "\n",
    "Exercise: for some reason, plotly is not showing the correct result. Could you please fix it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO   \n",
    "# 1. jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "# 2. change notebook to 'trusted'\n",
    "\n",
    "data = [plotly.graph_objs.Histogram(x=list(marys_pandas_DF['birthYear']),name=\"Plot\")]\n",
    "plotly.offline.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare popularity of two names from 1990."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "dordonDF = (peopleDF \n",
    "  .select(year(\"birthDate\").alias(\"birthYear\"), \"firstName\") \n",
    "  .filter((col(\"firstName\") == 'Donna') | (col(\"firstName\") == 'Dorothy')) \n",
    "  .filter(\"gender == 'F' \") \n",
    "  .filter(year(\"birthDate\") > 1990) \n",
    "  .orderBy(\"birthYear\") \n",
    "  .groupBy(\"birthYear\", \"firstName\") \n",
    "  .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birthYear</th>\n",
       "      <th>firstName</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991</td>\n",
       "      <td>Donna</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>Dorothy</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992</td>\n",
       "      <td>Donna</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992</td>\n",
       "      <td>Dorothy</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>Donna</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1993</td>\n",
       "      <td>Dorothy</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1994</td>\n",
       "      <td>Donna</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1994</td>\n",
       "      <td>Dorothy</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1995</td>\n",
       "      <td>Dorothy</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1995</td>\n",
       "      <td>Donna</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   birthYear firstName  count\n",
       "0       1991     Donna     27\n",
       "1       1991   Dorothy     25\n",
       "2       1992     Donna     30\n",
       "3       1992   Dorothy     39\n",
       "4       1993     Donna     22\n",
       "5       1993   Dorothy     28\n",
       "6       1994     Donna     26\n",
       "7       1994   Dorothy     21\n",
       "8       1995   Dorothy     26\n",
       "9       1995     Donna     33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(dordonDF) # html form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----+\n",
      "|birthYear|firstName|count|\n",
      "+---------+---------+-----+\n",
      "|     1991|  Dorothy|   25|\n",
      "|     1991|    Donna|   27|\n",
      "|     1992|    Donna|   30|\n",
      "|     1992|  Dorothy|   39|\n",
      "|     1993|    Donna|   22|\n",
      "|     1993|  Dorothy|   28|\n",
      "|     1994|  Dorothy|   21|\n",
      "|     1994|    Donna|   26|\n",
      "|     1995|    Donna|   33|\n",
      "|     1995|  Dorothy|   26|\n",
      "|     1996|    Donna|   23|\n",
      "|     1996|  Dorothy|   19|\n",
      "|     1997|  Dorothy|   24|\n",
      "|     1997|    Donna|   36|\n",
      "|     1998|    Donna|   28|\n",
      "|     1998|  Dorothy|   33|\n",
      "|     1999|    Donna|   22|\n",
      "|     1999|  Dorothy|   25|\n",
      "|     2000|  Dorothy|    4|\n",
      "|     2000|    Donna|    2|\n",
      "+---------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dordonDF.show() # text form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Could you please come up with some visualization for `dordonDF`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dordon_pandas_DF = dordonDF.toPandas()\n",
    "#plt.bar(dordon_pandas_DF['birthYear'], height=dordon_pandas_DF['count'], color='#86bf91')\n",
    "#plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary Views\n",
    "\n",
    "In DataFrames, <b>temporary views</b> are used to make the DataFrame available to SQL, and work with SQL syntax seamlessly.\n",
    "\n",
    "A temporary view gives you a name to query from SQL, but unlike a table it exists only for the duration of your Spark Session. As a result, the temporary view will not carry over when you restart the cluster or switch to a new notebook. It also won't show up in the Data button on the menu on the left side of a Databricks notebook which provides easy access to databases and tables.\n",
    "\n",
    "The statement in the following cells create a temporary view containing the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "peopleDF.createOrReplaceTempView(\"People10M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the contents of temporary view, use select notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>firstName</th>\n",
       "      <th>middleName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>ssn</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2595</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Carola</td>\n",
       "      <td>Philipot</td>\n",
       "      <td>F</td>\n",
       "      <td>1964-09-26 04:00:00</td>\n",
       "      <td>999-24-1601</td>\n",
       "      <td>63160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1043084</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Lidia</td>\n",
       "      <td>Clutram</td>\n",
       "      <td>F</td>\n",
       "      <td>1961-03-10 05:00:00</td>\n",
       "      <td>967-76-9652</td>\n",
       "      <td>100016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1896797</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Pamala</td>\n",
       "      <td>Roundtree</td>\n",
       "      <td>F</td>\n",
       "      <td>1989-10-15 04:00:00</td>\n",
       "      <td>907-98-6146</td>\n",
       "      <td>67723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3756906</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Jeanene</td>\n",
       "      <td>Aspland</td>\n",
       "      <td>F</td>\n",
       "      <td>1978-05-11 04:00:00</td>\n",
       "      <td>984-45-5643</td>\n",
       "      <td>56676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262706</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Shyla</td>\n",
       "      <td>Khosa</td>\n",
       "      <td>F</td>\n",
       "      <td>1957-12-06 05:00:00</td>\n",
       "      <td>990-45-5675</td>\n",
       "      <td>66505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2788507</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Candida</td>\n",
       "      <td>Antusch</td>\n",
       "      <td>F</td>\n",
       "      <td>1979-07-05 04:00:00</td>\n",
       "      <td>956-38-1959</td>\n",
       "      <td>65484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3533125</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Amira</td>\n",
       "      <td>Dillimore</td>\n",
       "      <td>F</td>\n",
       "      <td>1961-07-17 04:00:00</td>\n",
       "      <td>904-82-2741</td>\n",
       "      <td>66073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2625872</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Krissy</td>\n",
       "      <td>Leate</td>\n",
       "      <td>F</td>\n",
       "      <td>1971-10-21 04:00:00</td>\n",
       "      <td>962-86-1002</td>\n",
       "      <td>73115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>324633</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Eulalia</td>\n",
       "      <td>Stonestreet</td>\n",
       "      <td>F</td>\n",
       "      <td>1964-04-09 05:00:00</td>\n",
       "      <td>971-10-4374</td>\n",
       "      <td>106777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1945549</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Tenisha</td>\n",
       "      <td>Wellard</td>\n",
       "      <td>F</td>\n",
       "      <td>1994-07-05 04:00:00</td>\n",
       "      <td>931-97-5701</td>\n",
       "      <td>51420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id firstName middleName     lastName gender           birthDate  \\\n",
       "0     2595     Donna     Carola     Philipot      F 1964-09-26 04:00:00   \n",
       "1  1043084     Donna      Lidia      Clutram      F 1961-03-10 05:00:00   \n",
       "2  1896797     Donna     Pamala    Roundtree      F 1989-10-15 04:00:00   \n",
       "3  3756906     Donna    Jeanene      Aspland      F 1978-05-11 04:00:00   \n",
       "4   262706     Donna      Shyla        Khosa      F 1957-12-06 05:00:00   \n",
       "5  2788507     Donna    Candida      Antusch      F 1979-07-05 04:00:00   \n",
       "6  3533125     Donna      Amira    Dillimore      F 1961-07-17 04:00:00   \n",
       "7  2625872     Donna     Krissy        Leate      F 1971-10-21 04:00:00   \n",
       "8   324633     Donna    Eulalia  Stonestreet      F 1964-04-09 05:00:00   \n",
       "9  1945549     Donna    Tenisha      Wellard      F 1994-07-05 04:00:00   \n",
       "\n",
       "           ssn  salary  \n",
       "0  999-24-1601   63160  \n",
       "1  967-76-9652  100016  \n",
       "2  907-98-6146   67723  \n",
       "3  984-45-5643   56676  \n",
       "4  990-45-5675   66505  \n",
       "5  956-38-1959   65484  \n",
       "6  904-82-2741   66073  \n",
       "7  962-86-1002   73115  \n",
       "8  971-10-4374  106777  \n",
       "9  931-97-5701   51420  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(spark.sql(\"SELECT * FROM  People10M WHERE firstName = 'Donna' \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame with a more specific query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "womenBornAfter1990DF = (peopleDF \n",
    "  .select(\"firstName\", \"middleName\", \"lastName\",year(\"birthDate\").alias(\"birthYear\"), \"salary\") \n",
    "  .filter(year(\"birthDate\") > 1990) \n",
    "  .filter(\"gender = 'F' \") \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Temporary Views from the `womenBornAfter1990DF` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "womenBornAfter1990DF.createOrReplaceTempView(\"womenBornAfter1990\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a temporary view has been created, it can be queried as if it were a table. \n",
    "\n",
    "Find out how many Marys are in the WomenBornAfter1990 DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(1)\n",
       "0       268"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(spark.sql(\"SELECT count(*) FROM womenBornAfter1990 where firstName = 'Mary' \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Create a DataFrame called top10FemaleFirstNamesDF that contains the 10 most common female first names out of the people data set.\n",
    "\n",
    "* `firstName` - the first name\n",
    "* `total` - the total number of rows with that first name\n",
    "\n",
    "**Hint:** \n",
    "* You may need to break ties by using firstName because some of the totals are identical.\n",
    "* To restrict the number of names to 10, you need to use the `limit(10)` method.\n",
    "* You also need to use the `agg()` method to do a count of `firstName` and give it an alias.\n",
    "* The `agg()` method is applied after the `groupBy` since it requires column values to be collected in some fashion.\n",
    "* You will need to import the `count` and `desc` methods in Scala or Python, as appropriate.\n",
    "\n",
    "Display the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "Create a DataFrame called `top10FemaleFirstNamesDF` and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "from pyspark.sql.functions import count, desc\n",
    "\n",
    "top10FemaleFirstNamesDF = (peopleDF.select(\"firstname\")\n",
    "                           .filter(\"gender='F'\") \n",
    "                           .groupBy(\"firstName\") \n",
    "                           .count() \n",
    "                           .orderBy(desc(\"count\"), \"firstName\") \n",
    "                           .limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstName</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alesha</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice</td>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bridgette</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cristen</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jacquelyn</td>\n",
       "      <td>1381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Katherin</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lashell</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Louie</td>\n",
       "      <td>1382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lucille</td>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sharyn</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstName  count\n",
       "0     Alesha   1368\n",
       "1      Alice   1384\n",
       "2  Bridgette   1373\n",
       "3    Cristen   1375\n",
       "4  Jacquelyn   1381\n",
       "5   Katherin   1373\n",
       "6    Lashell   1387\n",
       "7      Louie   1382\n",
       "8    Lucille   1384\n",
       "9     Sharyn   1394"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10FemaleNamesDF = top10FemaleFirstNamesDF.orderBy(\"firstName\")\n",
    "\n",
    "display(top10FemaleNamesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Row(firstName='Alesha', count=1368) does not equal expected Row(firstName='Alesha', total=1368)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-cb470c592ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop10FemaleNamesDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdfTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DF-L2-names-0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirstName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu\"Alesha\"\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1368\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdfTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DF-L2-names-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirstName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu\"Alice\"\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1384\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdfTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DF-L2-names-2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirstName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu\"Bridgette\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1373\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8ecb11992c71>\u001b[0m in \u001b[0;36mdfTest\u001b[0;34m(id, expected, result)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdfTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{} does not equal expected {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Row(firstName='Alesha', count=1368) does not equal expected Row(firstName='Alesha', total=1368)"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "results = top10FemaleNamesDF.collect()\n",
    "\n",
    "dfTest(\"DF-L2-names-0\", Row(firstName=u\"Alesha\",    total=1368), results[0])  \n",
    "dfTest(\"DF-L2-names-1\", Row(firstName=u\"Alice\",     total=1384), results[1])\n",
    "dfTest(\"DF-L2-names-2\", Row(firstName=u\"Bridgette\", total=1373), results[2])\n",
    "dfTest(\"DF-L2-names-3\", Row(firstName=u\"Cristen\",   total=1375), results[3])\n",
    "dfTest(\"DF-L2-names-4\", Row(firstName=u\"Jacquelyn\", total=1381), results[4])\n",
    "dfTest(\"DF-L2-names-5\", Row(firstName=u\"Katherin\",  total=1373), results[5])\n",
    "dfTest(\"DF-L2-names-6\", Row(firstName=u\"Lashell\",   total=1387), results[6])\n",
    "dfTest(\"DF-L2-names-7\", Row(firstName=u\"Louie\",     total=1382), results[7])\n",
    "dfTest(\"DF-L2-names-8\", Row(firstName=u\"Lucille\",   total=1384), results[8])\n",
    "dfTest(\"DF-L2-names-9\", Row(firstName=u\"Sharyn\",    total=1394), results[9]) \n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Convert the DataFrame to a temporary view and display the contents of the temporary view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstName</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sharyn</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lashell</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice</td>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucille</td>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Louie</td>\n",
       "      <td>1382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jacquelyn</td>\n",
       "      <td>1381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cristen</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bridgette</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Katherin</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alesha</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstName  count\n",
       "0     Sharyn   1394\n",
       "1    Lashell   1387\n",
       "2      Alice   1384\n",
       "3    Lucille   1384\n",
       "4      Louie   1382\n",
       "5  Jacquelyn   1381\n",
       "6    Cristen   1375\n",
       "7  Bridgette   1373\n",
       "8   Katherin   1373\n",
       "9     Alesha   1368"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "top10FemaleFirstNamesDF.createOrReplaceTempView(\"Top10FemaleFirstNames\")\n",
    "resultsDF = spark.sql(\" SELECT * FROM Top10FemaleFirstNames \")\n",
    "display(resultsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy; 2019 [Intellinum Analytics, Inc](http://www.intellinum.co). All rights reserved.<br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark24_py36]",
   "language": "python",
   "name": "conda-env-pyspark24_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
